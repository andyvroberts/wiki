## Apache Spark
Spark can run with several underlying cluster managers, although from reading documentation, it seems to work best with Apache Hadoop as the storage manager and cluster framework (HDFS and Yarn).  

There is now an easy pyspark install for local development and/or testing purposes.  

### Python Install
```py
pip install pyspark
```